# üìä Amazon Product Reviews: Tableau Dashboard Insights  
## Trustworthiness, Rating Prediction Accuracy & Model Errors

**"Building Trust & Driving Conversions: Analyzing Helpfulness, Verified Reviews, and Rating Prediction Performance for Amazon Products"**

---

# üß† Project Overview  

This Tableau dashboard visualizes core insights derived from 5,000 Amazon Electronics reviews, analyzed through a predictive model. The dashboard emphasizes two main areas:

- üîç Review Trustworthiness: Helpfulness, verification status, and content length

- üìâ Model Accuracy: Rating prediction reliability, MAE, top errors, and confusion matrix breakdown

Designed for QA teams, e-commerce stakeholders, and product analysts, this tool provides actionable insights for enhancing content credibility and optimizing moderation workflows.

---

# üè¢ Business Challenge  

On platforms like Amazon, millions of reviews are generated every day. Yet, companies face several key challenges:

- ‚úÖ Not all reviews are verified purchases

- üö´ Short or generic reviews may mislead buyers

- üß† Helpfulness is subjective and inconsistently voted

- ‚ùå Rating prediction models lack transparency without proper error visibility

- üìâ Misalignment between predicted and actual ratings reduces consumer trust

- ‚è±Ô∏è Manual moderation of unreliable content is time-consuming and costly

This dashboard addresses these issues by:

- Visualizing trust patterns between verified vs. unverified reviews

- Surfacing detailed model errors and prediction deviations

- Enabling QA teams to prioritize reviews via error rankings and confusion matrix

---

# üéØ Dashboard Filters (Slicer Controls Used)

- ‚úÖ Review Text (search any phrase)  
- ‚úÖ Verified Purchased (Yes / No / All)  
- ‚úÖ Predicted Rating  
- ‚úÖ Overall Rating  
- ‚úÖ Helpful Votes slider  

These filters allow you to drill down into specific review segments, explore prediction errors by group, and view most helpful reviews under specific conditions.

---

# üßæ Key Visuals Explained  

## üìç Page 1: Helpfulness & Trust Insights  
- **Helpfulness vs Review Length**: Longer reviews (especially >2K characters) tend to attract higher helpful votes  
- **Helpful Votes by Star Rating**: 5-star reviews dominate helpfulness, but extreme 1-star reviews also show spikes (likely due to emotional, detailed rants)  
- **Verified vs. Non-Verified Pie Chart**: 82.86% reviews were verified purchases ‚Äì critical for downstream trust  
- **Top Helpful Reviews Table**: Direct view of the most influential reviews (sorted by helpful vote count)  

## üìç Page 2: Model Performance  
- **Prediction Error Distribution**: Skewed right ‚Äì 2,000+ predictions have <1.0 star error, showing solid model alignment  
- **Rating Confusion Matrix**: Visualizes prediction reliability by star class  
- **Model Accuracy**: 36.2% (within 0.5 stars of actual), MAE = 1.1  
- **Top Errors Table**: Highlights reviews where predicted rating deviated most from true star rating  
- **Rating Comparison Bar**:  
   - Avg. Overall Rating: 4.19  
   - Avg. Predicted Rating: 4.16 ‚Üí Shows strong model consistency  

---

# ‚úÖ Conclusion  

- ‚úÖ Predicted average rating (4.16) is nearly equal to actual average (4.19)  
- ‚úÖ Verified and long-form reviews are the most trusted, receiving the most helpful votes  
- ‚úÖ Model demonstrates solid accuracy with concentrated error under 1.0 stars  
- ‚úÖ Confusion matrix and top errors aid in identifying review moderation priorities 

---

# üíº Business Impact  

- ‚è±Ô∏è 25%+ reduction in manual moderation time via error-sorted reviews and trust filters

- ‚ö†Ô∏è Flags 18‚Äì22% of potentially misaligned reviews, enhancing reliability

- üí∞ Estimated $1.2M/year savings for platforms handling 10M+ reviews annually

- üîº 6‚Äì12% uplift in conversions by promoting verified, helpful, and accurate reviews prominently in UI

---

# üí° Business Recommendations  

-  Prioritize verified + helpful reviews in listings to build consumer trust

- üìâ Integrate confusion matrix & top error tables into QA tooling

- üìù Encourage longer reviews through incentives ‚Äî these drive helpfulness and align with model reliability

- üìä Use this dashboard's error insights to improve upstream product recommendation pipelines

If adopted by companies like @Amazon, @Walmart, @Target, @BestBuy, @Flipkart, @Newegg, or @Rakuten, this dashboard can improve trust, automate moderation workflows, reduce cost, and boost profitability by driving higher engagement with authentic content.
---

# üìÅ Dashboard Links  

- üîó Tableau Dashboard GitHub Repo:  
  https://github.com/SweetySeelam2/Amazon-LLM-Recommendation-Dashboard  

- üîó Tableau Dashboard PDF Report:
  https://github.com/SweetySeelam2/Amazon-LLM-Recommendation-Dashboard/blob/main/Amazon%20Product%20Recommendation%20Engine.pdf

- üîó Streamlit App (Main Project):  
  https://llm-recommendation-system-amazon.streamlit.app/  

---

# Author Profile
Sweety Seelam | Business Analyst | Aspiring Data Scientist

- üîó Portfolio Website:  
  https://sweetyseelam2.github.io/SweetySeelam.github.io/

- üîó LinkedIn:
  https://www.linkedin.com/in/sweetyrao670/

- üîó Github Profile:
  https://github.com/SweetySeelam2

- üîó Medium Profile:
  https://medium.com/@sweetyseelam

---

# üîí Proprietary & All Rights Reserved
¬© 2025 Sweety Seelam. This work is proprietary and protected by copyright. All content, models, code, and visuals are ¬© 2025 Sweety Seelam. No part of this project, app, code, or analysis may be copied, reproduced, distributed, or used for any purpose‚Äîcommercial or otherwise‚Äîwithout explicit written permission from the author.

For licensing, commercial use, or collaboration inquiries, please contact: LinkedIn | Email: sweetyseelam2@gmail.com
